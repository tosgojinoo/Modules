{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Models\n",
    "- Based on the 3rd place solution\n",
    "- Make different DNN models by changing only the random seed value\n",
    "- Ensemble the models using the power mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import platform\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For DNN modeling\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "# Tensorflow warning off\n",
    "if tf.__version__ <'2': \n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import * #Input, Dense\n",
    "from keras.models import * #Model\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.regularizers import *\n",
    "from keras.utils.np_utils import *\n",
    "from keras.utils.vis_utils import * #model_to_dot\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "f0a1c729d4fb3d6609f9dfb163ebe92fa9dc654c"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data.pkl')\n",
    "test  = pd.read_csv('test.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "5f4e4c5c552daf8d4da6999ae4b63f13459b2887"
   },
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "9af76d7b80064573a453e5e10c35b76fc31c47a4"
   },
   "outputs": [],
   "source": [
    "X_train = ...\n",
    "y_train = ...\n",
    "X_valid = ...\n",
    "y_valid = ...\n",
    "X_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118130, 42), (13481, 42))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Models\n",
    "Random seed 변경만을 통해 다수의 DNN 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형 학습 시 RMSE를 계산하는 함수\n",
    "import keras.backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매번 모델링을 할 때마다 동일한 결과를 얻으려면 아래 코드를 실행해야 함.\n",
    "def get_reproducible_model():\n",
    "    SEED = 1                    # seed 숫자를 지정\n",
    "    random.seed(SEED)           # Python 고정\n",
    "    np.random.seed(SEED)        # numpy 고정\n",
    "    if tf.__version__[0] < '2': # Tensorflow 고정\n",
    "        tf.set_random_seed(SEED)\n",
    "    else:\n",
    "        tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 사이즈 찾는 함수\n",
    "def FindBatchSize(model):\n",
    "    \"\"\"#model: model architecture, that is yet to be trained\"\"\"\n",
    "    import os, sys, psutil, gc, tensorflow, keras\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "    BatchFound= 16\n",
    "\n",
    "    try:\n",
    "        total_params= int(model.count_params());    GCPU= \"CPU\"\n",
    "        #find whether gpu is available\n",
    "        try:\n",
    "            if K.tensorflow_backend._get_available_gpus()== []:\n",
    "                GCPU= \"CPU\";    #CPU and Cuda9GPU\n",
    "            else:\n",
    "                GCPU= \"GPU\"\n",
    "        except:\n",
    "            from tensorflow.python.client import device_lib;    #Cuda8GPU\n",
    "            def get_available_gpus():\n",
    "                local_device_protos= device_lib.list_local_devices()\n",
    "                return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "            if \"gpu\" not in str(get_available_gpus()).lower():\n",
    "                GCPU= \"CPU\"\n",
    "            else:\n",
    "                GCPU= \"GPU\"\n",
    "\n",
    "        #decide batch size on the basis of GPU availability and model complexity\n",
    "        if (GCPU== \"GPU\") and (os.cpu_count() >15) and (total_params <1000000):\n",
    "            BatchFound= 64    \n",
    "        if (os.cpu_count() <16) and (total_params <500000):\n",
    "            BatchFound= 64  \n",
    "        if (GCPU== \"GPU\") and (os.cpu_count() >15) and (total_params <2000000) and (total_params >=1000000):\n",
    "            BatchFound= 32      \n",
    "        if (GCPU== \"GPU\") and (os.cpu_count() >15) and (total_params >=2000000) and (total_params <10000000):\n",
    "            BatchFound= 16  \n",
    "        if (GCPU== \"GPU\") and (os.cpu_count() >15) and (total_params >=10000000):\n",
    "            BatchFound= 8       \n",
    "        if (os.cpu_count() <16) and (total_params >5000000):\n",
    "            BatchFound= 8    \n",
    "        if total_params >100000000:\n",
    "            BatchFound= 1\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "\n",
    "        #find percentage of memory used\n",
    "        memoryused= psutil.virtual_memory()\n",
    "        memoryused= float(str(memoryused).replace(\" \", \"\").split(\"percent=\")[1].split(\",\")[0])\n",
    "        if memoryused >75.0:\n",
    "            BatchFound= 8\n",
    "        if memoryused >85.0:\n",
    "            BatchFound= 4\n",
    "        if memoryused >90.0:\n",
    "            BatchFound= 2\n",
    "        if total_params >100000000:\n",
    "            BatchFound= 1\n",
    "        print(\"Batch Size:  \"+ str(BatchFound));    gc.collect()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    memoryused= [];    total_params= [];    GCPU= \"\";\n",
    "    del memoryused, total_params, GCPU;    gc.collect()\n",
    "    return BatchFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FindBatchSize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값을 저장할 폴더 생성\n",
    "folder = 'Ensemble'\n",
    "if not os.path.isdir(folder):\n",
    "    os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [16:54<00:00, 101.48s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(10)):    \n",
    "    SEED = np.random.randint(1, 10000)              \n",
    "    random.seed(SEED)       \n",
    "    np.random.seed(SEED)     \n",
    "    if tf.__version__[0] < '2':  \n",
    "        tf.set_random_seed(SEED)\n",
    "    else:\n",
    "        tf.random.set_seed(SEED)\n",
    "    \n",
    "    # Define the NN architecture\n",
    "    input = Input(shape=(X_train.shape[1],))\n",
    "    x = Dense(64, activation='elu')(input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x1 = Dense(64)(x)\n",
    "    x = Add()([x1,x])\n",
    "    x = Dense(32, activation='elu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x1 = Dense(32)(x)\n",
    "    x = Add()([x1,x])\n",
    "    x = Dense(16, activation='elu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x1 = Dense(16)(x)\n",
    "    x = Add()([x1,x])\n",
    "    output = Dense(1)(x)\n",
    "    model = Model(input,output)  \n",
    "    \n",
    "    # Choose the optimizer and the cost function\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[rmse])\n",
    "    \n",
    "    # explain model\n",
    "    model.summary()\n",
    "    Image(model_to_dot(model,show_shapes=True, show_layer_names=False).create(prog='dot', format='png'))\n",
    "    \n",
    "    # Train the model\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=200)]\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=2048, epochs=200, \n",
    "                 callbacks=callbacks, shuffle=False, verbose=0)\n",
    "    \n",
    "    # plotting loss func.\n",
    "    plt.plot(hist.history['loss'], label=\"train loss\")\n",
    "    plt.plot(hist.history[\"val_loss\"], label=\"validation loss\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Make submissions\n",
    "    submission = pd.DataFrame({\n",
    "        \"xx\": test.item_id, \n",
    "        # (0~20)으로 범위를 제한할 경우\n",
    "        \"yy\": model.predict(X_test).clip(0, 20).flatten()\n",
    "    })\n",
    "    t = pd.Timestamp.now()\n",
    "    fname = f\"{folder}/dnn_submission_{t.month:02}{t.day:02}_s{SEED:05}.csv\"\n",
    "    submission.to_csv(fname, index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Models \n",
    "생성된 다수의 DNN 모형을 power mean하여 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = 0\n",
    "for f in os.listdir(folder):\n",
    "    ext = os.path.splitext(f)[-1]\n",
    "    if ext == '.csv': \n",
    "        s = pd.read_csv(folder+\"/\"+f)\n",
    "    else: \n",
    "        continue\n",
    "    if len(s.columns) !=2:\n",
    "        continue\n",
    "    if nf == 0: \n",
    "        slist = s\n",
    "    else: \n",
    "        slist = pd.merge(slist, s, on=\"item_id\")\n",
    "    nf += 1\n",
    "\n",
    "p = 4.5 # 이 값에 따라 성능이 달라짐 (p=1: 산술평균, p>1: 멱평균)    \n",
    "if nf >= 2:\n",
    "    pred = 0\n",
    "    for j in range(nf): pred = pred + slist.iloc[:,j+1]**p \n",
    "    pred = pred / nf    \n",
    "    pred = pred**(1/p)\n",
    "\n",
    "    submission = pd.DataFrame({'xx': slist.item_id, 'yy': pred})\n",
    "    t = pd.Timestamp.now()\n",
    "    fname = f\"p{p}mean_submission_{t.month:02}{t.day:02}_{t.hour:02}{t.minute:02}.csv\"\n",
    "    submission.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
